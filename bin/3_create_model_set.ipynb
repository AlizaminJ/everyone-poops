{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "blocks = pd.read_csv('data_census//tl_2010_06075_tabblock10.csv')\n",
    "caseid_block = pd.read_csv('caseid_block_all.csv')\n",
    "cases = pd.read_csv('311_cases_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the date range\n",
    "#'2016-05-01'\n",
    "date_range_use = pd.date_range('2018-04-01','2018-05-01', freq = '6H')\n",
    "\n",
    "# create the columns\n",
    "date_col = list(date_range_use)*len(blocks['GEOID10'].unique())\n",
    "block_col = sorted(list(blocks['GEOID10'].unique())*len(date_range_use))\n",
    "\n",
    "# create the empty matrix\n",
    "empty_matrix = pd.DataFrame({'Opened_rnd':date_col,\n",
    "                          'block_fips':block_col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the hour\n",
    "cases['hour'] = cases['Opened'].apply(lambda x:int(x[11:13]))\n",
    "\n",
    "def bin_hours(row):\n",
    "    \"\"\"\n",
    "    will group hours together in order to have bins instead of the raw timestamp\n",
    "    \"\"\"\n",
    "    if row['hour'] < 6:\n",
    "        return '0' \n",
    "    elif row['hour'] < 12:\n",
    "        return '6' \n",
    "    elif row['hour'] < 18:\n",
    "        return '12'\n",
    "    else:\n",
    "        return '18'\n",
    "\n",
    "# insert the rounded hour back into the dataframe\n",
    "cases['bin_hour'] = cases.apply(bin_hours, axis=1)\n",
    "cases['new_date'] = cases['Opened_rnd'].apply(lambda x:x[0:10])\n",
    "cases['Opened_rnd'] = cases['new_date'] + ' '+ cases['bin_hour'] + ':00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select appropriate columns\n",
    "caseid_block = caseid_block.loc[:,[\n",
    "    \n",
    "    'CaseID',\n",
    "    'block_fips',\n",
    "]]\n",
    "\n",
    "cases = cases.loc[:,[\n",
    "    \n",
    "    'CaseID',\n",
    "    'Opened_rnd',\n",
    "]]\n",
    "\n",
    "# join tables together\n",
    "case_block_date = cases.merge(caseid_block, on = 'CaseID')\n",
    "model_data = empty_matrix.merge(case_block_date,\n",
    "                                on = ['block_fips','Opened_rnd'],\n",
    "                                how = 'left')\n",
    "\n",
    "# create target feature\n",
    "model_data['poop'] = np.where(model_data['CaseID'].notnull(), 1, 0)\n",
    "model_data = model_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:1471: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->datetime,key->block2_values] [items->['Opened_rnd']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# save to hdf\n",
    "model_data.to_hdf('data_model//model_data_test.h5', key = 'xyz', complib = 'blosc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
